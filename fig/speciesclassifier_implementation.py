# -*- coding: utf-8 -*-
"""SpeciesClassifier-Implementation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Hll9DxrUGHYlKW3oju9SbiAguU81VGLm
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import models, transforms

import matplotlib.pyplot as plt
import numpy as np
from PIL import Image
import os
import datetime
import sys

dtype = torch.float
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
device

CLASSES = ['Acanthus ilicifolius', 'Acrostichum aureum', 'Avicennia alba', 'Avicennia marina', 'Bruguiera cylindrica', 'Bruguiera gymnorrihza', 'Ceriops tagal', 'Derris heterophylla', 'Excoecaria agallocha', 'Kandelia candel', 'Lumnizera recemosa', 'Rhizophora apiculata', 'Rhizophora mucronata', 'Sonneratia alba', 'Sonneratia caseolaris', 'Aegiceras corniculatum']

# Saved Model Location
resnet_model = "/Users/suhrudh/Desktop/ForestDeptProj/species_id/resnet18_full.pth"
vgg_model = "/Users/suhrudh/Desktop/ForestDeptProj/species_id/vgg_full.pth"

class ResnetModel(nn.Module):
    def __init__(self):
        super(ResnetModel, self).__init__()
        self.conv_net = models.resnet18(pretrained=True)
        self.conv_net.fc = nn.Linear(self.conv_net.fc.in_features, len(CLASSES))

        # Load the state dict from the drive after first train
        self.load_state_dict(torch.load(resnet_model, map_location=device))
        # Freeze the parameters of the convnet (if you want a feature extractor only)
        self.to(dtype).to(device)

    def forward(self, X):
        X = self.conv_net(X)
        # returns the class only
        _, preds = torch.max(X, 1)
        # Return both to use for training
        return X, preds

class VGGModel(nn.Module):
    def __init__(self):
        super(VGGModel, self).__init__()
        self.conv_net = models.vgg16(pretrained=True)
        self.conv_net.classifier[6] = nn.Linear(self.conv_net.classifier[6].in_features, len(CLASSES))

        # Load the state dict from the drive after first train
        self.load_state_dict(torch.load(vgg_model, map_location=device))
        # Freeze the parameters of the convnet (if you want a feature extractor only)
        self.to(dtype).to(device)

    def forward(self, X):
        X = self.conv_net(X)
        # returns the class only
        _, preds = torch.max(X, 1)
        # Return both to use for training
        return X, preds

class Classifier():
    def __init__(self):
        """Core Classifier class that is an ensemble of the two models"""
        self.resnet = ResnetModel()
        self.vgg = VGGModel()

        self.image_transform = transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
        self.resnet.eval()
        self.vgg.eval()
        
    def forward(self, path):
        image = Image.open(path)
        # Apply the transforms on the image
        image = self.image_transform(image)
        image = image.unsqueeze(0).to(device)

        X_resnet, preds_resnet = self.resnet(image)
        X_resnet = F.softmax(X_resnet, dim=-1)
        X_vgg, preds_vgg = self.vgg(image)
        X_vgg = F.softmax(X_vgg, dim=-1)

        return self.ensemble(X_resnet, X_vgg), X_resnet, X_vgg, preds_resnet, preds_vgg

    def ensemble(self, X_resnet, X_vgg):
        """Return the ensemble of both the networks"""
        X_ens = (X_resnet + X_vgg)*0.5
        _, preds = torch.max(X_ens, 1)
        return X_ens, preds

    def __call__(self, X):
        return self.forward(X)

    def predict_image(self, path, f=None, verbose=False):
        [X_ens, preds_ens], X_resnet, X_vgg, preds_resnet, preds_vgg = self.__call__(path)

        if f is not None:
            with open(f, "a") as file:
                file.write(f"File: {f}\n")
                file.write("Ensemble: \n")
                file.write(f"Predicted Class: {CLASSES[preds_ens]}\n")
                file.write("Classes Distribution:\n")
                for i, val_ in enumerate(X_ens[0]):
                    file.write(f"{i+1}. {CLASSES[i]}: {val_*100}\n")
                file.write("---\n")
                file.write("Resnet: \n")
                file.write(f"Predicted Class: {CLASSES[preds_resnet]}\n")
                file.write("Classes Distribution:\n")
                for i, val_ in enumerate(X_resnet[0]):
                    file.write(f"{i+1}. {CLASSES[i]}: {val_*100}\n")
                file.write("---\n")
                file.write("VGG: \n")
                file.write(f"Predicted Class: {CLASSES[preds_vgg]}\n")
                file.write("Classes Distribution:\n")
                for i, val_ in enumerate(X_vgg[0]):
                    file.write(f"{i+1}. {CLASSES[i]}: {val_*100}\n")
                file.write("---**---\n")
        else:
            print("Ensemble: ")
            print(f"Predicted Class: {CLASSES[preds_ens]}")
            print("Classes Distribution:")
            for i, val_ in enumerate(X_ens[0]):
                print(f"{i+1}. {CLASSES[i]}: {val_*100}")
            print("---")
            print()
            print("Resnet: ")
            print(f"Predicted Class: {CLASSES[preds_resnet]}")
            print("Classes Distribution:")
            for i, val_ in enumerate(X_resnet[0]):
                print(f"{i+1}. {CLASSES[i]}: {val_*100}")
            print("---")
            print()
            print("VGG: ")
            print(f"Predicted Class: {CLASSES[preds_vgg]}")
            print("Classes Distribution:")
            for i, val_ in enumerate(X_vgg[0]):
                print(f"{i+1}. {CLASSES[i]}: {val_*100}")
            print("---**---")

        if not verbose:
            return preds_ens.item()
        else:
            return preds_ens.item(), preds_resnet.item(), preds_vgg.item(), X_ens, X_resnet, X_vgg

    def predict_from_folder(self, path, logging):
        files = os.listdir(path)
        population = np.zeros((len(CLASSES),))
        for img in files:
            try:
                preds_ens = self.predict_image(os.path.join(path, img), logging)
                population[preds_ens] += 1
            except Exception as e:
                print(f"[WARN] Bad file {img}")
        print(population)
        logging = logging.replace(".log", "-final.log")
        with open(logging, "a") as file:
            file.write(f"Path: {path}/n")
            file.write("Detected Percentages:\n")
            for i, entry in enumerate(population):
                file.write(f"{CLASSES[i]}: {entry*100/len(files)}\n")

# image = "/Users/suhrudh/Desktop/ForestDeptProj/chapora"
# classifier = Classifier()

# classifier.predict_from_folder(image, "naroa.log")