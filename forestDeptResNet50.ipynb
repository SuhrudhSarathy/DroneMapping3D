{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "forestDeptResNet50.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1zpjUM9G5SxqFnbQ1ugyWYjLizYYUztyH",
      "authorship_tag": "ABX9TyMWEL8IPTTYJB/NMUzFdQAk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bharat787/ForestDeptProj/blob/master/forestDeptResNet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2b851DtkuU5",
        "colab_type": "text"
      },
      "source": [
        "# Import all libraries\n",
        "main libraries include keras, numpy, cv2, and os"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkEmhjBK5wdM",
        "colab_type": "code",
        "outputId": "e98a5bbc-15f9-49d0-c7f6-c23c9f67ea7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import cv2\n",
        "import os\n",
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.utils import to_categorical\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.utils import plot_model\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ta6s6XABv4Wr",
        "colab_type": "text"
      },
      "source": [
        "# Identity Block\n",
        "In this model we are experimenting with ResNet50 architecture.\n",
        "\n",
        "The identity block is the standard block used in ResNets, and corresponds to the case where the input activation (say  a^[l] ) has the same dimension as the output activation (say  a^[l+2] )."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLmPA_b7Ryyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Second component of main path (≈3 lines)\n",
        "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path (≈2 lines)\n",
        "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    \n",
        "    \n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcMgobiHwy36",
        "colab_type": "text"
      },
      "source": [
        "# Convulational Block\n",
        "The ResNet \"convolutional block\" is the second block type. You can use this type of block when the input and output dimensions don't match up. The difference with the identity block is that there is a CONV2D layer in the shortcut path.\n",
        "\n",
        "* The CONV2D layer in the shortcut path is used to resize the input  xx  to a different dimension, so that the dimensions match up in the final addition needed to add the shortcut value back to the main path. \n",
        "* For example, to reduce the activation dimensions's height and width by a factor of 2, you can use a 1x1 convolution with a stride of 2.\n",
        "* The CONV2D layer on the shortcut path does not use any non-linear activation function. Its main role is to just apply a (learned) linear function that reduces the dimension of the input, so that the dimensions match up for the later addition step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R9AhJkfYVZc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Second component of main path (≈3 lines)\n",
        "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    # Third component of main path (≈2 lines)\n",
        "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH #### (≈2 lines)\n",
        "    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '1', kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    return X\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeteYuO-xNJN",
        "colab_type": "text"
      },
      "source": [
        "# Defining ResNet50\n",
        "Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5CCtoVEYjl3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ResNet50(input_shape = (64, 64, 3), classes = 2):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    # Stage 3 (≈4 lines)\n",
        "    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 (≈6 lines)\n",
        "    X = convolutional_block(X, f=3, filters=[256, 256, 1024], stage=4, block='a', s=2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 (≈3 lines)\n",
        "    X = X = convolutional_block(X, f=3, filters=[512, 512, 2048], stage=5, block='a', s=2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X = AveragePooling2D(pool_size=(2, 2), padding='same')(X)\n",
        "    \n",
        "\n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQ8YDNOLY2S7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initializing the model\n",
        "\n",
        "model = ResNet50(input_shape = (64, 64, 3), classes = 2 )\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xB-uDg3dxkYA",
        "colab_type": "text"
      },
      "source": [
        "Since colab doesn't support cv2.imshow() we import a patch workaround cv2_imshow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzUSIJxkZKs0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcfj8kXgxyCC",
        "colab_type": "text"
      },
      "source": [
        "# Load data and Preprocess\n",
        "Find the path to your folder using the files menu on the right(if using colab) or use the path in your local system Preprocessing includes resizing to input size(here, 64x64), converting to numpy array, labelling the images, shuffling the whole dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AcBE7h1a62v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# code to preprocess and load data\n",
        "\n",
        "# initialize the data and labels list\n",
        "print(\"[INFO] loading images...\")\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "# grab the image paths and randomly shuffle them\n",
        "imagePaths = '/content/drive/My Drive/forestdata/dataset/Mngroves' # address path\n",
        "for filename in os.listdir(imagePaths):\n",
        "    if filename.endswith(\"jpg\"):                                   # change if other format\n",
        "        # Your code comes here such as \n",
        "        fname = ('/content/drive/My Drive/forestdata/dataset/Mngroves/' + str(filename)) # total path by joining path + filename\n",
        "        image = cv2.imread(fname)\n",
        "        #cv2_imshow(image)\n",
        "        image = cv2.resize(image, (64, 64))  # 64 x 64 is input to resnet\n",
        "        image = img_to_array(image)\n",
        "        data.append(image)\n",
        "       \n",
        "        # get the labels\n",
        "        label = fname.split(os.path.sep)[-2]\n",
        "        label = 1 if label == \"Mngroves\" else 0\n",
        "        labels.append(label)\n",
        "print('all done')   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCwvzX-Ikt4_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imagePaths = '/content/drive/My Drive/forestdata/dataset/NtMngroves'\n",
        "for filename in os.listdir(imagePaths):\n",
        "    if filename.endswith(\"jpg\"): \n",
        "        # Your code comes here such as \n",
        "        fname = ('/content/drive/My Drive/forestdata/dataset/NtMngroves/' + str(filename))\n",
        "        print(fname)\n",
        "        \n",
        "        image = cv2.imread(fname)\n",
        "        #cv2_imshow(image)\n",
        "        image = cv2.resize(image, (64, 64))  # 64 x 64 is input to resnet\n",
        "        image = img_to_array(image)\n",
        "        data.append(image)\n",
        "       \n",
        "        # get the labels\n",
        "        label = fname.split(os.path.sep)[-2]\n",
        "        label = 1 if label == \"Mngroves\" else 0\n",
        "        labels.append(label)\n",
        "print('all done')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRXqaNIGzFY7",
        "colab_type": "text"
      },
      "source": [
        "# Shuffling data\n",
        "Done so as to prevent classifer to tune to one class over the other also both data and labels are shuffled in unison so that corresponding image and label remain the same."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZTmqNhuw0GQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rng_state = np.random.get_state()     # random state is kept the same so that\n",
        "np.random.shuffle(data)               # both get same order whilst shuffling\n",
        "np.random.set_state(rng_state)\n",
        "np.random.shuffle(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGtvE6pOzK3h",
        "colab_type": "text"
      },
      "source": [
        "# Split Data and Create test and train sets\n",
        "We will keep a proportion of images as trainset (here 75%) as train set rest as test set(25%). The random state helps to keep the test and train split always same to help debug while training the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TjcdGJHw2OV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(trainX, testX, trainY, testY) = train_test_split(data,\n",
        "\tlabels, test_size=0.25, random_state=42)\n",
        "print(type(trainY))\n",
        "print(type(trainY))\n",
        "data = np.array(data, dtype=\"float\") / 255.0\n",
        "labels = np.array(labels)\n",
        "\n",
        "# convert the labels from integers to vectors\n",
        "trainY = to_categorical(trainY, num_classes=2)  # classification of 2 only\n",
        "testY = to_categorical(testY, num_classes=2) \n",
        "print (\"number of training examples = \" + str(trainX.shape[0]))\n",
        "print (\"number of test examples = \" + str(testX.shape[0]))\n",
        "print (\"X_train shape: \" + str(trainX.shape))\n",
        "print (\"Y_train shape: \" + str(trainY.shape))\n",
        "print (\"X_test shape: \" + str(testX.shape))\n",
        "print (\"Y_test shape: \" + str(testY.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmrPvSTzzVqS",
        "colab_type": "text"
      },
      "source": [
        "# Training and predicting the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WP4qX24Aw6Ca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(trainX, trainY, epochs = 100, batch_size = 32)\n",
        "'''\n",
        " too many epochs may cause your model to over-fit the training data. It means \n",
        " that your model does not learn the data, it memorizes the data\n",
        " Generally batch size of 32 or 25 is good, with epochs = 100 unless you have \n",
        " large dataset. in case of large dataset you can go with batch size of 10 with\n",
        "  epochs b/w 50 to 100.\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_l0zpjBxEFa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = model.evaluate(testX, testY)\n",
        "print (\"Loss = \" + str(preds[0]))\n",
        "print (\"Test Accuracy = \" + str(preds[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlhUiQUXzwWz",
        "colab_type": "text"
      },
      "source": [
        "Testing with your image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGde83cw4uOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_path = '/content/drive/My Drive/forestdata/dataset/Mngroves/Mngroves1.jpg'\n",
        "#img = image.load_img(img_path, target_size=(64, 64))\n",
        "image = cv2.imread(img_path)\n",
        "#cv2_imshow(image)\n",
        "image = cv2.resize(image, (64, 64))\n",
        "image = img_to_array(image)\n",
        "x = image\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = x/255.0\n",
        "print('Input image shape:', x.shape)\n",
        "cv2_imshow(image)\n",
        "print(\"class prediction vector [p(0), p(1) = \")\n",
        "print(model.predict(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8N-nGYCCY8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_path = '/content/drive/My Drive/forestdata/dataset/Mngroves/Mngroves1.jpg'\n",
        "image = cv2.imread(img_path)\n",
        "image = cv2.resize(image, (1024, 1024))\n",
        "cv2_imshow(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K53N2nUKviOw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "v"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}